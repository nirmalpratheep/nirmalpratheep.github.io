<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description"
        content="Nirmal Pratheep Natarajan - AI/ML Engineering Leader | LLM Training, Agentic AI, Deep RL">
    <title>Nirmal Pratheep Natarajan | AI/ML Engineering Leader</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles.css">
</head>

<body>
    <div class="page-wrapper">
        <div class="container">
            <!-- Sidebar -->
            <aside class="sidebar">
                <div class="profile">
                    <div class="avatar">NP</div>
                    <h1 class="name">Nirmal Pratheep Natarajan</h1>
                    <p class="tagline">AI/ML Engineering Leader</p>
                    <p class="tagline-sub">AMD &middot; 13+ Years</p>
                </div>
                <nav class="nav-links">
                    <a href="#summary">Summary</a>
                    <a href="#leadership">Leadership & Impact</a>
                    <a href="#expertise">Core Expertise</a>
                    <a href="#experience">Experience</a>
                    <a href="#projects">Select Projects</a>
                    <a href="#publications">Publications</a>
                    <a href="#skills">Skills & Education</a>
                </nav>
                <nav class="social-links">
                    <a href="mailto:nirmalpratheep@gmail.com">&#9993; Email</a>
                    <a href="https://github.com/nirmalpratheep" target="_blank">&#8984; GitHub</a>
                    <a href="https://linkedin.com/in/nirmalpratheep" target="_blank">in LinkedIn</a>
                </nav>
            </aside>

            <!-- Main Content -->
            <main class="main-content">

                <!-- Summary -->
                <section class="section" id="summary">
                    <p class="bio">
                        <strong>13+ years</strong> building and leading AI/ML teams at AMD &amp; Xilinx.
                        I convert ideas to production &mdash; LLM training, agentic systems,
                        and deep RL &mdash; while leading <strong>10+ engineers</strong> across global sites.
                    </p>
                </section>

                <!-- Leadership & Impact -->
                <section class="section" id="leadership">
                    <h2>Leadership & Impact</h2>
                    <div class="impact-grid">
                        <div class="impact-card">
                            <div class="impact-source">AMD</div>
                            <div class="impact-metric">10+</div>
                            <div class="impact-label">Engineers Led</div>
                            <p>Technical lead of cross-site teams across AMD global locations, driving architecture
                                decisions and delivering complex multi-quarter projects</p>
                        </div>
                        <div class="impact-card">
                            <div class="impact-source">AMD</div>
                            <div class="impact-metric">3x</div>
                            <div class="impact-label">System Throughput</div>
                            <p>Architected distributed client/server system for simulation tooling on next-generation
                                FPGA nodes (10nm/7nm/2nm)</p>
                        </div>
                        <div class="impact-card">
                            <div class="impact-source">AMD</div>
                            <div class="impact-metric">20x</div>
                            <div class="impact-label">Scale Improvement</div>
                            <p>Designed divide-and-conquer parallel processing via LSF Farm, enabling 20x larger chip
                                versions</p>
                        </div>
                        <div class="impact-card">
                            <div class="impact-source">Open Source</div>
                            <div class="impact-metric">14.2x</div>
                            <div class="impact-label">Reasoning Gain</div>
                            <p>LLM alignment pipeline (SFT &rarr; GRPO RL) achieving 14.2x zero-shot reasoning on
                                Qwen 2.5 Math 1.5B</p>
                        </div>
                        <div class="impact-card">
                            <div class="impact-source">Open Source</div>
                            <div class="impact-metric">33%</div>
                            <div class="impact-label">Training Throughput</div>
                            <p>1B parameter model pre-training optimization via custom Triton kernels and fused Flash
                                Attention</p>
                        </div>
                        <div class="impact-card">
                            <div class="impact-source">Open Source</div>
                            <div class="impact-metric">90%+</div>
                            <div class="impact-label">Agent Success Rate</div>
                            <p>Multi-stage agentic pipeline with LangGraph, prompt engineering, memory, and
                                iterative self-correction</p>
                        </div>
                    </div>
                </section>

                <!-- Core Expertise -->
                <section class="section" id="expertise">
                    <h2>Core Expertise</h2>
                    <div class="expertise-grid">
                        <div class="expertise-item">
                            <strong>LLM Pre-training & Optimization</strong>
                            <span>Dense/Sparse architectures, Flash Attention, Triton kernels, ZeRO/FSDP/DeepSpeed,
                                mixed-precision training, GPU profiling (Nsight)</span>
                        </div>
                        <div class="expertise-item">
                            <strong>LLM Post-training & Alignment</strong>
                            <span>SFT, GRPO, RLHF pipelines, TRL/vLLM integration, Optuna hyperparameter optimization,
                                reward modeling</span>
                        </div>
                        <div class="expertise-item">
                            <strong>Agentic AI Systems</strong>
                            <span>Multi-agent architectures, LangGraph/LangChain orchestration, autonomous code
                                generation, Docker-based evaluation frameworks</span>
                        </div>
                        <div class="expertise-item">
                            <strong>Deep Reinforcement Learning</strong>
                            <span>Environment design, GNN feature extraction, policy optimization for combinatorial
                                problems, Ray distributed training</span>
                        </div>
                        <div class="expertise-item">
                            <strong>Distributed Systems & Infrastructure</strong>
                            <span>Ray, LSF, Kubernetes, multi-GPU pipelines, large-scale data processing (3.5B+
                                datapoints), graph compression</span>
                        </div>
                        <div class="expertise-item">
                            <strong>AI for Semiconductor Design (EDA)</strong>
                            <span>ML-driven delay prediction, RL-based floorplan optimization, GNN for design complexity
                                analysis, model monitoring & drift detection</span>
                        </div>
                    </div>
                </section>

                <!-- Professional Experience -->
                <section class="section" id="experience">
                    <h2>Professional Experience</h2>

                    <div class="experience-entry">
                        <div class="exp-header">
                            <strong>AMD</strong> (formerly Xilinx)
                            <span class="exp-tenure">2012 &ndash; Present &middot; San Jose, CA</span>
                        </div>
                        <div class="exp-role">Senior Staff / Technical Lead &mdash; AI/ML & Design Automation</div>

                        <div class="exp-section-label">Applied AI/ML for EDA</div>
                        <ul>
                            <li>Researched and developed <strong>Deep RL for directive optimization</strong> using
                                GIN (Graph Isomorphism Network) for feature extraction on netlists up to
                                <strong>15M nodes</strong>; achieved 2% placement quality improvement replacing manual
                                tuning; published at <strong>GTAC'25 (Finalist)</strong></li>
                            <li>Developed <strong>Agentic AI framework</strong> using LangGraph and LLMs for
                                <strong>autonomous triage</strong> with iterative self-correction and Dockerized
                                orchestration</li>
                            <li>Built <strong>ML delay prediction algorithms</strong> and <strong>GNN-based design
                                    complexity models</strong> with automated fine-tuning, model monitoring, and
                                drift detection; published at <strong>GTAC'22 (Finalist)</strong></li>
                            <li>Built <strong>Ray-based distributed training</strong> infrastructure with Grid, ASHA,
                                and PBT hyperparameter search for scalable RL model training</li>
                        </ul>

                        <div class="exp-section-label">Technical Leadership & Systems Engineering</div>
                        <ul>
                            <li><strong>Led 10+ engineer team</strong> across global sites for simulation delay capture
                                tooling on <strong>10nm/7nm/2nm FPGA nodes</strong>; mentored and guided engineers
                                through design and development</li>
                            <li>Architected <strong>client/server system</strong> (Boost Asio + Google Protobuf)
                                enabling concurrent multi-capture with <strong>3x throughput</strong> improvement</li>
                            <li>Designed <strong>divide-and-conquer parallel processing</strong> system via LSF Farm,
                                enabling <strong>20x larger chip versions</strong> compared to initial chip size</li>
                            <li>Built <strong>graph compression pipeline</strong> processing 3.5B datapoints, reducing
                                1B instance paths to 500K patterns with Python analytics and visualization</li>
                            <li>Developed tool profiling, linters, debugging dashboards, and automatic <strong>YAML
                                    semantic verifier</strong> auto code generation for HW/SW assumption validation</li>
                        </ul>
                    </div>
                </section>

                <!-- Select Projects -->
                <section class="section" id="projects">
                    <h2>Select Open Source Projects</h2>
                    <div class="project-grid">
                        <div class="project-card">
                            <strong><a href="https://github.com/nirmalpratheep/Alignment_and_Reasoning_RL"
                                    target="_blank">LLM Alignment & Reasoning RL</a></strong>
                            <p>End-to-end alignment pipeline: Baseline &rarr; SFT &rarr; GRPO RL on Qwen 2.5 Math 1.5B.
                                14.2x accuracy gain (2.84% &rarr; 40.46%), TRL GRPOTrainer with vLLM colocate, dual-GPU
                                Optuna + ASHA optimization.</p>
                            <span class="project-links">
                                <a href="https://wandb.ai/nirmalpratheep-self/math-sft-optuna-asha"
                                    target="_blank">W&B HPO</a>
                                <a href="https://wandb.ai/nirmalpratheep-self/math-sft" target="_blank">W&B SFT</a>
                                <a href="https://wandb.ai/nirmalpratheep-self/math-grpo-trl" target="_blank">W&B
                                    GRPO</a>
                            </span>
                        </div>
                        <div class="project-card">
                            <strong>1B Seed Model Pre-training</strong>
                            <p>Optimized 1B Dense parameter model (75% GDN, 25% GSA with midpoint reversibility).
                                33% throughput gain via Triton kernels, Flash Attention. Profiled with Nsight
                                Systems/Compute.</p>
                        </div>
                        <div class="project-card">
                            <strong><a href="https://github.com/nirmalpratheep/SmolLMv2-PreTrain"
                                    target="_blank">SmolLM v2 Pre-training</a></strong>
                            <p>Pre-trained 135M parameter model on FineWeb-Edu with Flash Attention. ~40k tokens/sec
                                throughput using Mixed Precision (BF16); loss reduction from 11.6 to 0.0015.</p>
                        </div>
                        <div class="project-card">
                            <strong><a href="https://github.com/nirmalpratheep/codingAgent"
                                    target="_blank">Agentic Coding Pipeline</a></strong>
                            <p>Multi-stage bug fixing pipeline with LangGraph orchestration, prompt engineering,
                                memory management, AST-based analysis, iterative self-correction with linter
                                verification. 90%+ success rate.</p>
                        </div>
                        <div class="project-card">
                            <strong><a href="https://github.com/nirmalpratheep/SWE-AgentBench"
                                    target="_blank">SWE-Agent Benchmark</a></strong>
                            <p>Multi-agent evaluation system with 3-agent architecture and Docker-based test isolation
                                on SWE-bench dataset for automated LLM benchmarking.</p>
                        </div>
                        <div class="project-card">
                            <strong><a href="https://github.com/nirmalpratheep/ImageNetClassifier"
                                    target="_blank">ImageNet Classifier</a></strong>
                            <p>ResNet-50 trained on ImageNet-1K achieving 77.4% Top-1 accuracy. CutMix, MixUp, Random
                                Erasing augmentations with LR Finder optimization.</p>
                        </div>
                    </div>
                    <p class="more-projects">
                        More:
                        <a href="https://github.com/nirmalpratheep/MiniTamilBPETokenizer" target="_blank">Tamil BPE
                            Tokenizer</a> &middot;
                        <a href="https://github.com/nirmalpratheep/RL-CarNavigationAgent" target="_blank">RL Car
                            Navigation</a> &middot;
                        <a href="https://github.com/nirmalpratheep/CIFAR100-Resnet34" target="_blank">CIFAR-100
                            ResNet-34</a> &middot;
                        <a href="https://github.com/nirmalpratheep/MNISTImageClassifier-ArchitectureExploration"
                            target="_blank">MNIST Architecture Search</a>
                    </p>
                </section>

                <!-- Publications -->
                <section class="section" id="publications">
                    <h2>Publications & Recognition</h2>
                    <ul class="pub-list">
                        <li><strong>Deep RL for FloorPlan Optimization</strong> &mdash; GTAC'25 & SPS Tech Conference
                            <em>(Finalist, arXiv pending)</em>
                        </li>
                        <li><strong>ML-based Delay Prediction</strong> &mdash; GTAC'22 AMD Tech Conference
                            <em>(Finalist)</em>
                        </li>
                        <li><strong>Adaptive OFDM Pilots</strong> &mdash; IEEE WAMICON 2009</li>
                        <li><strong>Top 15</strong> &mdash; Innovate India Design Contest (ALTERA), 2007</li>
                        <li><strong>Elite Mentorship Program</strong> &mdash; AMD</li>
                    </ul>
                </section>

                <!-- Skills & Education -->
                <section class="section two-col" id="skills">
                    <div>
                        <h2>Technical Skills</h2>
                        <p><strong>ML/DL Frameworks:</strong> PyTorch, HuggingFace, TRL, vLLM, DeepSpeed, FSDP</p>
                        <p><strong>RL & Agents:</strong> Stable Baselines 3, Ray, Gym, LangGraph, LangChain</p>
                        <p><strong>Languages:</strong> Python, C++, Golang</p>
                        <p><strong>Infrastructure:</strong> Kubernetes, Docker, Ray, LSF, PostgreSQL, MongoDB</p>
                        <p><strong>GPU Profiling:</strong> Nsight Systems, Nsight Compute, PyTorch Profiler, Triton</p>
                    </div>
                    <div id="education">
                        <h2>Education</h2>
                        <p><strong>M.Eng</strong> Electrical Engineering &mdash; University of Cincinnati, 2012</p>
                        <p><strong>B.Eng</strong> Electronics & Communication &mdash; Anna University, 2007</p>
                        <h2 class="subsection-heading">Certifications</h2>
                        <p class="cert-line">
                            Triton Kernel Dev on AMD Instinct GPUs &middot;
                            LLM Serving with vLLM & MI300X &middot;
                            Agentic Framework (HuggingFace) &middot;
                            Generative AI with LLMs (DeepLearning.AI) &middot;
                            ML Ops (DeepLearning.AI) &middot;
                            Machine Learning (Stanford) &middot;
                            Analytics Edge (MITx) &middot;
                            Parallel & Distributed Computing (Rice) &middot;
                            Kubernetes (Udacity) &middot;
                            Big Data with Spark (Berkeley)
                        </p>
                    </div>
                </section>

            </main>
        </div>
    </div>
    <footer class="footer">&copy; 2025 Nirmal Pratheep Natarajan</footer>
</body>

</html>