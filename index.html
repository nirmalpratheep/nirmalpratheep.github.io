<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description"
        content="Nirmal Pratheep Natarajan - AI/ML Research Engineer | LLM Training, Deep RL, Performance Optimization">
    <title>Nirmal Pratheep Natarajan | AI/ML Research Engineer</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles.css">
</head>

<body>
    <div class="page-wrapper">
        <div class="container">
            <!-- Sidebar -->
            <aside class="sidebar">
                <div class="profile">
                    <div class="avatar">NP</div>
                    <h1 class="name">Nirmal Pratheep Natarajan</h1>
                    <p class="tagline">AI/ML Research Engineer</p>
                    <p class="tagline-sub">AMD &middot; 13+ Years</p>
                </div>
                <nav class="nav-links">
                    <a href="#summary">Summary</a>
                    <a href="#research">Research & Publications</a>
                    <a href="#benchmarks">Benchmarks & Results</a>
                    <a href="#experience">Experience</a>
                    <a href="#engineering">Engineering Projects</a>
                    <a href="#skills">Skills & Education</a>
                </nav>
                <nav class="social-links">
                    <a href="mailto:nirmalpratheep@gmail.com">&#9993; Email</a>
                    <a href="https://github.com/nirmalpratheep" target="_blank">&#8984; GitHub</a>
                    <a href="https://linkedin.com/in/nirmalpratheep" target="_blank">in LinkedIn</a>
                </nav>
            </aside>

            <!-- Main Content -->
            <main class="main-content">

                <!-- Summary -->
                <section class="section" id="summary">
                    <p class="bio">
                        <strong>13+ years</strong> at AMD &amp; Xilinx turning ML research into production systems.
                        LLM training &amp; alignment, deep RL, GPU kernel optimization, and agentic AI.
                        Published researcher. Mentored teams of <strong>10+ engineers</strong> across global sites.
                    </p>
                </section>

                <!-- Research & Publications -->
                <section class="section" id="research">
                    <h2>Research & Publications</h2>
                    <div class="research-grid">
                        <div class="research-card">
                            <div class="research-venue">AMD Internal Conference &middot; Finalist</div>
                            <strong>Deep RL for FloorPlan Optimization</strong>
                            <p>Formulated FPGA floorplan directive optimization as an RL problem.
                                Designed GIN-based graph feature extraction on netlists up to 15M nodes.
                                Achieved 2% placement quality improvement over manual expert tuning.
                                <em>(arXiv pending)</em></p>
                        </div>
                        <div class="research-card">
                            <div class="research-venue">AMD Internal Conference &middot; Finalist</div>
                            <strong>ML-based Delay Prediction for EDA</strong>
                            <p>Developed ML delay prediction models and GNN-based design complexity analysis
                                with automated fine-tuning, model monitoring, and drift detection pipelines.</p>
                        </div>
                        <div class="research-card">
                            <div class="research-venue">IEEE WAMICON 2009</div>
                            <strong>Adaptive OFDM Pilots</strong>
                            <p>Research on adaptive pilot placement for OFDM wireless communication systems.</p>
                        </div>
                        <div class="research-card">
                            <strong>LLM Alignment &amp; Reasoning via RL</strong>
                            <p>End-to-end alignment pipeline (Baseline &rarr; SFT &rarr; GRPO RL) on Qwen 2.5 Math 1.5B.
                                14.2x zero-shot accuracy gain with systematic ablation across training stages.
                                <a href="https://github.com/nirmalpratheep/Alignment_and_Reasoning_RL" target="_blank">Code</a> &middot;
                                <a href="https://wandb.ai/nirmalpratheep-self/math-grpo-trl" target="_blank">W&B</a></p>
                        </div>
                    </div>
                    <ul class="pub-list" style="margin-top: 14px;">
                        <li><strong>Top 15</strong> &mdash; Innovate India Design Contest (ALTERA), 2007</li>
                        <li><strong>Elite Mentorship Program</strong> &mdash; AMD</li>
                    </ul>
                </section>

                <!-- Benchmarks & Key Results -->
                <section class="section" id="benchmarks">
                    <h2>Benchmarks & Key Results</h2>
                    <div class="impact-grid">
                        <div class="impact-card">
                            <div class="impact-source">LLM Alignment</div>
                            <div class="impact-metric">14.2x</div>
                            <div class="impact-label">Reasoning Gain</div>
                            <p>Qwen 2.5 Math 1.5B: Baseline 2.84% &rarr; SFT 26% &rarr; GRPO 40.46% zero-shot accuracy.
                                Systematic ablation across training stages.</p>
                        </div>
                        <div class="impact-card">
                            <div class="impact-source">Pre-training</div>
                            <div class="impact-metric">33%</div>
                            <div class="impact-label">Throughput Gain</div>
                            <p>1B parameter model pre-training: custom Triton kernels, fused Flash Attention,
                                profiled with Nsight Systems/Compute.</p>
                        </div>
                        <div class="impact-card">
                            <div class="impact-source">Deep RL</div>
                            <div class="impact-metric">2%</div>
                            <div class="impact-label">Placement QoR</div>
                            <p>RL-based directive optimization on 15M-node graphs, replacing manual expert tuning.
                                GIN feature extraction + Ray distributed training.</p>
                        </div>
                        <div class="impact-card">
                            <div class="impact-source">Agentic AI</div>
                            <div class="impact-metric">90%+</div>
                            <div class="impact-label">Agent Success Rate</div>
                            <p>Multi-stage agentic pipeline with graph-based orchestration,
                                prompt engineering, AST analysis, and iterative self-correction.</p>
                        </div>
                        <div class="impact-card">
                            <div class="impact-source">Systems</div>
                            <div class="impact-metric">3x</div>
                            <div class="impact-label">Throughput</div>
                            <p>Distributed client/server architecture for simulation tooling on
                                next-generation FPGA nodes (10nm/7nm/2nm).</p>
                        </div>
                        <div class="impact-card">
                            <div class="impact-source">Systems</div>
                            <div class="impact-metric">20x</div>
                            <div class="impact-label">Scale</div>
                            <p>Divide-and-conquer parallel processing via LSF Farm for chip simulation,
                                enabling 20x larger designs.</p>
                        </div>
                    </div>
                </section>

                <!-- Professional Experience -->
                <section class="section" id="experience">
                    <h2>Professional Experience</h2>

                    <div class="experience-entry">
                        <div class="exp-header">
                            <strong>AMD</strong> (formerly Xilinx)
                            <span class="exp-tenure">2012 &ndash; Present &middot; San Jose, CA</span>
                        </div>
                        <div class="exp-role">Senior Staff / Research Engineer &mdash; AI/ML & Design Automation</div>

                        <div class="exp-section-label">Research & ML Systems</div>
                        <ul>
                            <li>Researched and implemented <strong>Deep RL for directive optimization</strong>:
                                designed environment, reward shaping, and GIN-based feature extraction on netlists
                                up to <strong>15M nodes</strong>; published at <strong>AMD Internal Conference (Finalist)</strong></li>
                            <li>Built <strong>Ray-based distributed training</strong> infrastructure with Grid, ASHA,
                                and PBT hyperparameter search for systematic experiment management and scalable RL training</li>
                            <li>Developed <strong>ML delay prediction algorithms</strong> and <strong>GNN-based design
                                    complexity models</strong> with automated fine-tuning, model monitoring, and
                                drift detection; published at <strong>AMD Internal Conference (Finalist)</strong></li>
                            <li>Built <strong>Agentic AI framework</strong> with multi-step orchestration and LLMs for
                                <strong>autonomous triage</strong> with iterative self-correction and Dockerized
                                evaluation</li>
                        </ul>

                        <div class="exp-section-label">Performance Engineering & Infrastructure</div>
                        <ul>
                            <li><strong>Mentored 10+ engineer team</strong> across global sites for simulation delay capture
                                tooling on <strong>10nm/7nm/2nm FPGA nodes</strong></li>
                            <li>Architected <strong>client/server system</strong> (Boost Asio + Google Protobuf)
                                enabling concurrent multi-capture with <strong>3x throughput</strong> improvement</li>
                            <li>Designed <strong>divide-and-conquer parallel processing</strong> system via LSF Farm,
                                enabling <strong>20x larger chip versions</strong></li>
                            <li>Built <strong>graph compression pipeline</strong> processing 3.5B datapoints, reducing
                                1B instance paths to 500K patterns with Python analytics and visualization</li>
                            <li>Developed tool profiling, linters, debugging dashboards, and <strong>YAML
                                    semantic verifier</strong> auto code generation for HW/SW validation</li>
                        </ul>
                    </div>
                </section>

                <!-- Research Engineering Projects -->
                <section class="section" id="engineering">
                    <h2>Research Engineering Projects</h2>
                    <div class="project-grid">
                        <div class="project-card">
                            <strong><a href="https://github.com/nirmalpratheep/Alignment_and_Reasoning_RL"
                                    target="_blank">LLM Alignment & Reasoning RL</a></strong>
                            <p>Implemented end-to-end alignment pipeline: Baseline &rarr; SFT &rarr; GRPO RL on Qwen 2.5 Math 1.5B.
                                14.2x accuracy gain (2.84% &rarr; 40.46%). TRL GRPOTrainer with vLLM colocate,
                                dual-GPU Optuna + ASHA hyperparameter optimization.</p>
                            <span class="project-links">
                                <a href="https://wandb.ai/nirmalpratheep-self/math-sft-optuna-asha"
                                    target="_blank">W&B HPO</a>
                                <a href="https://wandb.ai/nirmalpratheep-self/math-sft" target="_blank">W&B SFT</a>
                                <a href="https://wandb.ai/nirmalpratheep-self/math-grpo-trl" target="_blank">W&B
                                    GRPO</a>
                            </span>
                        </div>
                        <div class="project-card">
                            <strong>1B Seed Model Pre-training</strong>
                            <p>Optimized 1B Dense parameter model (75% GDN, 25% GSA with midpoint reversibility).
                                33% throughput gain via custom Triton kernels, fused Flash Attention.
                                Profiled with Nsight Systems/Compute for kernel-level bottleneck analysis.</p>
                        </div>
                        <div class="project-card">
                            <strong><a href="https://github.com/nirmalpratheep/SmolLMv2-PreTrain"
                                    target="_blank">SmolLM v2 Pre-training</a></strong>
                            <p>Implemented 135M parameter model pre-training on FineWeb-Edu with Flash Attention.
                                ~40k tokens/sec throughput using Mixed Precision (BF16); loss reduction from 11.6 to 0.0015.</p>
                        </div>
                        <div class="project-card">
                            <strong><a href="https://github.com/nirmalpratheep/codingAgent"
                                    target="_blank">Agentic Coding Pipeline</a></strong>
                            <p>Multi-stage bug fixing pipeline with graph-based orchestration, prompt engineering,
                                memory management, AST-based analysis, iterative self-correction with linter
                                verification. 90%+ success rate on benchmarks.</p>
                        </div>
                        <div class="project-card">
                            <strong><a href="https://github.com/nirmalpratheep/SWE-AgentBench"
                                    target="_blank">SWE-Agent Benchmark</a></strong>
                            <p>Multi-agent evaluation system with 3-agent architecture and Docker-based test isolation
                                on SWE-bench dataset for reproducible automated LLM benchmarking.</p>
                        </div>
                        <div class="project-card">
                            <strong><a href="https://github.com/nirmalpratheep/ImageNetClassifier"
                                    target="_blank">ImageNet Classifier</a></strong>
                            <p>ResNet-50 trained on ImageNet-1K achieving 77.4% Top-1 accuracy. CutMix, MixUp, Random
                                Erasing augmentations with LR Finder optimization.</p>
                        </div>
                    </div>
                    <p class="more-projects">
                        More:
                        <a href="https://github.com/nirmalpratheep/MiniTamilBPETokenizer" target="_blank">Tamil BPE
                            Tokenizer</a> &middot;
                        <a href="https://github.com/nirmalpratheep/RL-CarNavigationAgent" target="_blank">RL Car
                            Navigation</a> &middot;
                        <a href="https://github.com/nirmalpratheep/CIFAR100-Resnet34" target="_blank">CIFAR-100
                            ResNet-34</a> &middot;
                        <a href="https://github.com/nirmalpratheep/MNISTImageClassifier-ArchitectureExploration"
                            target="_blank">MNIST Architecture Search</a>
                    </p>
                </section>

                <!-- Skills & Education -->
                <section class="section two-col" id="skills">
                    <div>
                        <h2>Technical Skills</h2>
                        <p><strong>ML/DL Frameworks:</strong> PyTorch, HuggingFace, TRL, vLLM, DeepSpeed, FSDP</p>
                        <p><strong>RL & Agents:</strong> Stable Baselines 3, Ray, Gym, multi-agent orchestration</p>
                        <p><strong>GPU & Performance:</strong> Triton, Flash Attention, Nsight Systems/Compute, CUDA, mixed-precision</p>
                        <p><strong>Languages:</strong> Python, C++, Golang</p>
                        <p><strong>Infrastructure:</strong> Kubernetes, Docker, Ray, LSF, W&B, Optuna</p>
                    </div>
                    <div id="education">
                        <h2>Education</h2>
                        <p><strong>M.Eng</strong> Electrical Engineering &mdash; University of Cincinnati, 2012</p>
                        <p><strong>B.Eng</strong> Electronics & Communication &mdash; Anna University, 2007</p>
                        <h2 class="subsection-heading">Certifications</h2>
                        <p class="cert-line">
                            Triton Kernel Dev on AMD Instinct GPUs &middot;
                            LLM Serving with vLLM & MI300X &middot;
                            Agentic Framework (HuggingFace) &middot;
                            Generative AI with LLMs (DeepLearning.AI) &middot;
                            ML Ops (DeepLearning.AI) &middot;
                            Machine Learning (Stanford) &middot;
                            Analytics Edge (MITx) &middot;
                            Parallel & Distributed Computing (Rice) &middot;
                            Kubernetes (Udacity) &middot;
                            Big Data with Spark (Berkeley)
                        </p>
                    </div>
                </section>

            </main>
        </div>
    </div>
    <footer class="footer">&copy; 2025 Nirmal Pratheep Natarajan</footer>
</body>

</html>